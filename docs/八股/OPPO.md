1. deep research

自主进行网络检索、整合信息、分析数据、解答。

2. 多agent

协调模式	核心理念	典型技术/框架	适用场景
集中规划-分散执行	将自然语言指令解析为统一的任务图，由中央规划器分配任务，智能体分散执行。	FLEET 框架	异构机器人团队的任务调度、物流仓储
协同进化	智能体在互动中通过内在奖励相互学习，共同进化，无需外部监督。	CoMAS 框架	开放环境下的持续学习与适应，如游戏、模拟社交
记忆与对话驱动	智能体像人类团队一样，通过对话共享记忆、对齐意图、协作创造。	NTT "AI Constellation"	复杂的商业规划、跨部门战略制定
分层混合协作	在小群体内采用中心化规划，在群体间采用去中心化通信，兼顾效率与规模。	ReCA 框架	大规模具身智能系统（如机器人集群）的实时协作
策略融合	通过在线推断其他智能体的目标，动态混合多个预设策略，以适配不同的伙伴。

4. agent链路

5. 智能体全流程

6. 训练数据配比

7. transformer

encoder：双向，看到所有（bert）适合理解，不能生成
decoder：单向，掩码，适合生成

8. moe ffn/attention

传统稠密模型： 在传统的 Transformer 模型中，每一个输入 token 都会激活整个网络的所有参数。对于一个拥有 1000 亿参数的模型，处理一个 token 就需要动用全部 1000 亿参数。这导致计算成本（FLOPs）和推理延迟非常高。

MoE 模型： MoE 的核心思想是 “分而治之”。它将一个庞大的网络分解为多个更小的、功能各异的子网络，这些子网络被称为 “专家”。

对于每一个输入的 token，一个特殊的 “门控网络” 会动态地决定哪些（或哪个）专家最适合处理它。

最终，只有 被选中的少数专家 会被激活并参与计算，其他专家则保持“休眠”状态。

通过attention后，转移到不同专家的ffn。

9. reasoning model

10. SFT关注指标

11. adam

比起SDG，adam的学习率是自适应的（多改变->学习率小），避免震荡。