## SFT

### 有限资源下的SFT微调

*主流/通用级的代码生成任务模型参数量一般在7B-34B中间，难以在极其有限资源下运行；如果采用量化版本，则会一定程度上降低模型能力。在对模型泛化性要求较低的情况下，小模型微调也可以表现出很好的效果。*

  - **选择Qwen2.5-Coder-1.5B-Instruct模型用于微调**，兼顾训练效果与硬件要求
  - **选择Code Alpaca和TACO作为训练数据集**，从约4万条原数据中精选出1万条左右高质量数据用于训练；**采用MBPP和BigCodeBench数据集进行测试**，将训练集与测试集完全分离，评测真实的模型能力
  - **利用极其有限的显卡资源，训练代码生成模型并对结果进行调优。** 对1.5B模型在单卡4060训练（显存仅8G），实际内存占用仅有7000MB左右
  - **训练后，MBPP、MBPP+和BigCodeBench指标均得到提升。** 其中，MBPP和MBPP+指标提升约10个百分点，BigCodeBench指标也有少量提升，超过若干7B、13B等模型

---

### 问题

**在“大模型量化”和“小模型精调”这两个有限资源方案中，你为何最终选择了后者？**

**除了文中提到的“降低模型能力”，量化还有哪些潜在弊端？小模型精调的优势和上限在哪里？**  

**模型选型： 为什么选择 Qwen2.5-Coder-1.5B-Instruct 而不是其他同尺寸模型（如 StarCoder, CodeLlama）？**

**你提到“对模型泛化性要求较低”，请具体说明这个项目的目标场景是什么？哪些特性表明了对泛化性要求低？这是否意味着模型只擅长生成与训练集相似风格的代码？**



“从约4万条原数据中精选出1万条左右高质量数据”——你的“精选”标准和流程是什么？

Code Alpaca 和 TACO 数据集各有什幺特点和侧重？你为什么认为这两者的组合是有效的？它们之间是否存在冗余或互补？

在将不同来源的数据集混合时，你是如何统一它们的提示词（Prompt）格式的？有没有针对代码生成任务设计特定的提示词模板？

训练参数与技巧：

在仅有的8GB显存下，你是如何确定批量大小（batch size）、学习率等超参数的？是否使用了梯度累积？

有没有使用LoRA、QLoRA等参数高效微调技术？如果用了，为什么选择？参数（如 rank）是如何设定的？如果没用，为什么？全参数微调在1.5B模型上是否必要？

训练过程中是否监控了损失曲线？有没有出现过拟合的迹象？你是如何应对的（如早停、权重衰减）？

三、 评估与结果分析（What）
这部分考察你是否能科学地评估模型效果，并有理有据地分析结果。

评测集选择： 为什么选择 MBPP 和 BigCodeBench 作为测试集？它们分别评估了模型哪些方面的能力？（MBPP：基础编程逻辑；BigCodeBench：更复杂、真实的编程任务）

结果深度解读：

**MBPP/MBPP+ 提升约10个百分点，这个提升是绝对意义还是相对意义？**

BigCodeBench 提升较小，你认为可能的原因是什么？是否因为训练数据（Code Alpaca, TACO）与BigCodeBench的任务复杂性不匹配？

“超过若干7B、13B等模型”，这些是哪些模型？是它们的基座模型还是指令微调后的模型？这个比较是否公平？（例如，比较的可能是对方的基础模型，而非指令微调后的模型）。这个结果说明了什么？是说明你的微调方法好，还是说明“小模型+高质量数据”的潜力巨大？

案例分析： 能否展示一个或多个具体的例子，说明微调后的模型在哪些方面比原模型有明显改善？同时，能否展示一个模型仍然失败的案例，并分析原因？

四、 项目反思与延伸（What‘s Next）
这是展示你批判性思维和未来视野的关键部分。

错误分析： 如果你有时间对模型产生的错误代码进行系统分析，最常见的错误类型是什么？是语法错误、逻辑错误，还是无法理解复杂需求？

局限性： 你认为当前这个项目最大的局限性是什么？是模型规模的天花板、训练数据的质量和数量，还是评估方式的单一性？

如果资源翻倍： 如果你的显存不是8G而是24G，你会如何改进这个项目？是选择微调一个7B的模型，还是为1.5B模型提供更多、更高质量的数据？为什么？

超越代码生成： 代码生成任务除了通过单元测试（Pass@k），你认为还有哪些重要的评估维度？（例如：代码可读性、安全性、效率等）。你的项目如何考量这些因素？

### 参考论文

[Small Models are Valuable Plug-ins for Large Language Models](https://www.baidu.com)

[Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning](https://arxiv.org/pdf/2412.09906)