1. SFT 训练时，数据规模和模型大小之间有什么 scaling law？  
2. PEFT 的四种模式（addition, replace, LoRA, prompt tuning）分别讲讲（实现/优势）？  
3. SFT和强化学习的使用场景或者用途差别？  
4. SFT微调之后表现不好有什么原因  
5. FP16和BF16区别
6. LoRA 初始化怎么做的，用的秩是多少，为什么不选其他的数