## 熟练运用LoRA、QLoRA、Prefix Tuning、Adapter Tuning

仅微调一部分参数的方法称为高效微调。

### Lora

- 预训练模型有极小的内在维度 -> 内在秩

A随机，B为0  
原参数冻结，反向传播计算梯度时跳过

作用在Linear层：q、k、v

测试结果：
- 所有参数都在一个部分微调结果不好
- 平均分配q、v效果最佳

可以合并

### QLora

4-bit量化、双量化、分页

### Adapter Tuning

在transformer的每个ffn/attention后插入一个小神经网络模块；下投影、非线性激活函数、上投影、參差连接

无法合并

### Prefix Tuning

不修改内部权重，序列开头添加可训练向量

prefix：每层的k、v  
prompt：输入层

直接优化连续的Prefix向量（可训练参数）会导致训练不稳定和性能下降，因为这些向量的分布与模型经过多层网络后产生的激活值分布可能存在差异。  
解决方案：用一个小神经网络（MLP）生成向量，优化神经网络参数

## 熟悉 ReAct、ToT、CoT 等推理框架

### ReAct

推理与行动  

死循环防护、工具调用错误处理

### CoT

思维链：通过prompt使大模型生成中间推理步骤，模拟人类解决问题的流程

实现：few-shot/zero-shot

自洽性：生成多条推理链，投票选择最一致的选项


## 深入了解 RAG 全流程极其优化，包括文档解析、切分策略、向量检索、重排序等

### 幻觉

后验幻觉检测：

1. 白盒：基于不确定性/隐藏状态
2. 黑盒：简单采样（错误多个回答逻辑不一致）/规则（统计学指标、命名实体）/知识、工具增强（外部验证）/检测模型